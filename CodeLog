Test 7 isn't consistent.
=-=2 - Fri Dec  4 18:17:19 PST 2009

Toy examples done. url -> related docs.
Data structures now starting to take shape.

Tests are ugly, code interleaved with data.
We can use more indexes.
Decouple the index like in SQL, so the same code runs faster if the index
exists.
=-=4 - Fri Dec  4 19:14:31 PST 2009

Finished building the index. gen-docs works.
=-=5 - Sat Dec  5 09:47:15 PST 2009
Added agg3 ui to it. Messy that I've added stations to the flat-history model.
  Form to create new station.
  Choose between stations, each station gets its own read-list.
=-=6 - Mon Dec  7 13:22:11 PST 2009

Importing agg3 crawl pipeline. Next step: merge properly.

Vision: crawl a universal set of feeds. Don't wait for entire crawl to import
crawled feeds. Track per-user feeds and feed priorities in userinfo*. Make
agg3 just another station for users who import feeds. Push station selection
to a new screen; add new station form to the left panel when reading. Track
history by station.

Later: screens to manage feeds. Stations for importing email, other data
sources, etc. Discovering new feeds during crawl.
=-=7 - Tue Dec  8 12:06:08 PST 2009

crawl and htmlclean now communicate by fifo.
But it's currently blocking. So htmlclean blocks until input, then just reads
the first input and goes back to waiting. Meanwhile if I add a delay to
htmlclean it blocks crawl instead.
=-=8 - Tue Dec  8 14:11:15 PST 2009
If we stick with the blocking model we need to start the pipeline in reverse
order, from consumer to producer of each fifo.

If any stage dies, all other stages will block.

Will we lose stuff in fifos if we kill arc? Periodically look at files under
urls/
=-=9 - Tue Dec  8 15:06:09 PST 2009
Redefine defscan to run in separate threads, not a single thread.
Also some reorg.
=-=10 - Tue Dec  8 18:16:09 PST 2009

3 Crawl errors fixed.
=-=11 - Tue Dec  8 19:34:06 PST 2009

Instead of printing progress for background threads, maintain a circular
buffer of messages for each.
Not persistent for now.
=-=12 - Tue Dec  8 22:34:02 PST 2009

Focusing on UI.
Yesterday's problem: we want to scan read-list for both gen-docs and rendering
history.
=-=14 - Tue Dec  8 22:48:22 PST 2009

Ok, partial matches now working. Takes too long, though. Do all the work in
one pass. Every page load should do just one pass through docinfo*.
=-=15 - Tue Dec  8 23:24:59 PST 2009
Single pass for site-docs and feed-docs takes test runtime down from 72s to
42s for 13650 items in docinfo. But it's still too much.
=-=16 - Tue Dec  8 23:54:18 PST 2009
All that time is being spent on downcase!
Just add downcase versions of all metadata.
Or cache downcase separately.
=-=17 - Wed Dec  9 00:00:57 PST 2009
Yep, cached downcase and got to within 3x of non-downcase version.
=-=18 - Wed Dec  9 00:04:45 PST 2009

Time to start indexing. It's working, but dies every now and then. I think
it's dying when the pipe breaks.
=-=19 - Wed Dec  9 00:35:19 PST 2009
Ok, found the core dump in keywords.cc - negative index.
=-=21 - Thu Dec 10 00:44:08 PST 2009
Cleanup.
=-=22 - Thu Dec 10 00:46:41 PST 2009

Back to the UI. Refactoring index.arc to always take a user arg.
gen-docs doesn't like docs as arguments. I need to test-drive this..
=-=23 - Fri Dec 11 04:55:14 PST 2009
Done. Rebuilding the index.
=-=24 - Fri Dec 11 08:10:24 PST 2009

Lots of reorg, getting tests to pass.
Framework for gen-docs:
  generate candidates using doc-filters* and misc-filters*
  constraints to filter candidates
  score remaining candidates
=-=27 - Fri Dec 11 22:41:22 PST 2009

Trying to redo transparent persistence.
  Avoid unnecessary writes based on palsecam's idea.
  Write to new files so we have backups, and to eliminate any chance of data loss.
Doesn't work yet. I just realized save-registry needs to store references to
variables, not names.
Which means if I assign to a persistent variable I will lose persistence on it.
=-=30 - Sun Dec 13 19:53:37 PST 2009
Ok, save-registry now indexes by reference. But still not working. What's
going on?

Two bugs:
  a) (hash key) searches by value, even if what is stored in the hash is a
  reference. What's more it's searching by value at the time of insertion.
  Weird.
  b) buffered-exec isn't wiping when it should.
=-=31 - Sun Dec 13 20:43:03 PST 2009
Ah, it's a *hash* table. It's storing by reference but the hash is computed by
value.
  http://arclanguage.org/item?id=10984
It just shouldn't store by reference. That makes it too confusing.

Got the new transparent persistence working.
=-=32 - Mon Dec 14 01:23:05 PST 2009
Bugfix: snapshots were never being loaded.
=-= - Mon Dec 14 11:30:12 PST 2009

Getting readwarp up on AWS.
After all that testing turns out I never tested the metadata scan. It was
emitting strings with quotes escaped. Fixed.
=-=33 - Wed Dec 16 01:30:36 PST 2009
More bugfixing.
=-=36 - Thu Dec 17 17:18:00 PST 2009
Compute affinity graph by feed rather than url.

But it was taking too long; dhash wasn't working right. Ah, I never did
implement the nilcache idea to avoid recomputation.
Bring back old state.arc tests as well.
=-=37 - Thu Dec 17 19:55:41 PST 2009
Still struggling to compute feed affinity graph.
It's too slow. Let's switch to shell pipes. Dev speed includes performance
when experiments are this intensive and iterations this frequent.
=-=39 - Fri Dec 18 21:21:02 PST 2009

New python script to try normalizing overlap by keyword between feeds - each
keyword distributes 1/n to n*n feed connections.
We're seeing some quality. Krugman's blog is kinda well-connected to financial
blogs or blogs with kinda financial content.

Next steps:
  a signal for article-article overlap to help get at financial posts within
  say larry cheng's feed
  improve html cleaning to remove spurious overlap

Let's see if we can get by without changing keywords algo.
=-=41 - Sat Dec 19 15:29:31 PST 2009

Focusing on html cleaning now. First step: workflow to add tests to a corpus.
=-=42 - Sun Dec 20 15:25:27 PST 2009
Test script up and running.
=-=46 - Sun Dec 20 19:42:33 PST 2009
Added failing test cases by searching for commonly-occurring sets of keywords.
Just make one test case from each such set, that gives us 53 failing tests.
Ok, we've now got our work cut out for us.
=-=49 - Mon Dec 21 01:01:44 PST 2009

I need to add hints from feed descriptions. Step 1: crawl feeds to save
descriptions.
=-=50 - Tue Dec 22 12:23:03 PST 2009
Step 2: use the deschint: if it exists return the highest-scoring node that
contains the hint as a substring.

Unicode errors; I'm going over this tutorial:
  http://docs.python.org/howto/unicode.html
=-=51 - Tue Dec 22 13:55:41 PST 2009
=-=52 - Tue Dec 22 20:16:06 PST 2009
Turns out sorting by score then searching for a superset of deschint isn't
working.
=-=53 - Wed Dec 23 00:12:14 PST 2009
Fixed. 12 more tests passing.
=-=54 - Wed Dec 23 00:28:47 PST 2009
Evaluating the html cleaning process. We have 4 kinds of errors:
  Fixating on common content, either subtitles or sidebar
  Picking a comment instead of the post, usually when there's lots of comments
    slashdot, etc.
  Picking too much
  Picking too little
We've been under-estimating how well deschint does because these failures
aren't in their feeds anymore. Let's manually add hints, then try it on live
data.
=-=57 - Wed Dec 23 12:50:21 PST 2009
Hints manually added; 23 more tests pass, 31 still failing.
=-=59 - Wed Dec 23 13:50:59 PST 2009
Focussing on tweets. Why is so little matching?
=-=60 - Wed Dec 23 14:18:07 PST 2009
difflib limitation. Switched to http://code.google.com/p/google-diff-match-patch
Now we're down to 10 failing tests, but with two caveats:
  a) The new code is *much* slower. 150 tests took 34 minutes, which used to
  take ~1-2 minutes.
  b) We're probably under-counting failures because too-loose failures no
  longer get detected.
=-=61 - Wed Dec 23 15:55:08 PST 2009
Simple dilution metric to identify failing tests. 0.6 seems like a reasonable
boundary, but we're gonna occasionally get it wrong.
It's only for identifying failing tests, though. Let's focus on making them
pass more unequivocally.
=-=62 - Wed Dec 23 16:26:47 PST 2009
=-=63 - Wed Dec 23 17:55:01 PST 2009
Debugged the dilution metric. 50 of yesterday's tests are now reclassified as
failing, but I'm finally certain I'm not over-counting.

This took too long. I'd introduced a bug in fuzzymatch, then spent all day
staring at fuzzycheck.
=-=65 - Thu Dec 24 11:30:08 PST 2009
Cleanup.
=-=66 - Thu Dec 24 12:02:12 PST 2009
4 regressions compared to rev 57.
=-=68 - Thu Dec 24 14:38:07 PST 2009
Lost momentum yday thinking diff-match-patch too had issues as a difflib.

After adding a couple of test cases today I realize the problem isn't the diff
algo, but beautifulSoup. When the html breaks it inserts close tags in the
wrong place.
=-=69 - Fri Dec 25 20:59:34 PST 2009
No, even the html parsing is fine. So how are we getting close tags in the
wrong place?
=-=70 - Fri Dec 25 21:09:51 PST 2009
Ah, it's the substitution of <br> pairs for <p>'s. Then the <p> within the
table confuses BeautifulSoup.
=-=71 - Fri Dec 25 21:16:42 PST 2009
  [Accidentally committed htmlclean.py@60. Back to 68.
  =-=72 - Fri Dec 25 21:25:12 PST 2009]
It's a simple fix! Replace with <p>, not </p><p>. The close tag causes grief.
=-=73 - Fri Dec 25 21:30:24 PST 2009
Ok, convinced myself I don't really have regressions, the new failures are
because of tighter checks.
=-=77 - Sat Dec 26 12:35:32 PST 2009
=-=79 - Sun Dec 27 10:33:47 PST 2009

Back to arc. Loose html cleaning is ok for now - we'll at least get the
content of the article. Getting the whole html is prob bad, but let's see how
far we get with what we have.

New ds: feed-list*
Resisting the urge to create a fun defrep macro.
=-=81 - Mon Dec 28 21:42:49 PST 2009
Clean out old implementation. Let's just get keyword->seed feed working for
starters. Typing in 'cnn' should show a story from cnn.com
=-=82 - Mon Dec 28 21:51:38 PST 2009

Update crawl to record some feed metadata.
No author, sadly.
=-=83 - Tue Dec 29 18:15:04 PST 2009
Ah, just save feed description.
=-=86 - Wed Dec 30 11:52:59 PST 2009
First cut of kwd->feed. Too slow.
=-=89 - Thu Dec 31 04:36:33 PST 2009
Indexing feedinfo now. kwd-feeds can now help locate seed feeds.
=-=90 - Fri Jan  1 18:15:12 PST 2010
kwd-feeds now done.
scan-doc-dir: Finding docs that aren't in docinfo.

Also some new utils.
Start creating data structures more willy-nilly. We're almost there. Build,
then refactor.
=-=91 - Sun Jan  3 20:08:08 PST 2010
scan-doc-dir ended up costing me a whole day.
When I work without deliberation I can make boneheaded decisions like this.
And now snapshots.docinfo takes over 15 minutes to load.
=-=92 - Mon Jan  4 11:26:01 PST 2010
feed-affinity graph: Translate feedgraph.py into arc.
=-=93 - Mon Jan  4 17:29:39 PST 2010
feed-affinity graph implemented, not yet operationalized so I don't know how
to incrementally update it.
Too many pieces of the pipeline are having trouble scaling. I need to figure
out why.
  Start gc'ing documents.
=-=95 - Mon Jan  4 23:49:30 PST 2010
Ok, we were out of disk, that explains the slow initialization.
feed-affinity graph is easy to incrementally update. After the initial run
start calling update-normalized-keyword-clusters for each feed as it rolls in.
=-=96 - Tue Jan  5 09:38:02 PST 2010
shadow macro: dynamic binding so I can run tests on index functions without
having the fixtures clobber my shite.
We'll still lose changes while the tests run, though.
=-=97 - Tue Jan  5 12:53:30 PST 2010
another helper: shadow all persistent variables.
=-=98 - Tue Jan  5 14:23:55 PST 2010
index.arc.t will now run properly without touching real indexes.
Its tests still fail though.
=-=99 - Tue Jan  5 14:34:50 PST 2010

Workspace. Test driving several primitives.
=-=102 - Tue Jan  5 18:27:31 PST 2010
Done test-driving propagate primitives. This shouldn't have been so hard.
=-=104 - Wed Jan  6 00:04:08 PST 2010
Playing around with propagate. Added reinforce to boost candidates without
creating new ones.
Several sources of error in updating feeds. Moving back to the backend.
=-=106 - Wed Jan  6 12:21:09 PST 2010
Some tune-up.
Spent too long rebuilding the data structures. Again, shouldn't have been so
hard.
=-=107 - Wed Jan  6 14:26:37 PST 2010
Ok, incremental updates to data structures now working.
=-=109 - Wed Jan  6 15:24:45 PST 2010
Putting all the pieces together. Propagate working, but we just keep
propagating docs to keywords. We need to pick some other items each time to
propagate to more docs.
=-=113 - Thu Jan  7 18:54:43 PST 2010
Workspace entries now know their age in iters. Iter = up-vote.
First-cut of prune.
Code is functional, passes all tests, responsive. We still never leave the
seed feeds.
=-=115 - Fri Jan  8 00:17:02 PST 2010
Add only unread docs to workspace.
=-=116 - Fri Jan  8 00:36:55 PST 2010
Propagate-to-doc working, we're starting to see new feeds gradually pop up.
=-=117 - Fri Jan  8 10:50:20 PST 2010
Diversity - no more consecutive stories from a feed.
=-=118 - Fri Jan  8 11:29:28 PST 2010
Some bugfixes as I move past my 'krugman' test case to a 'burrito justice'
station.
Time to get on the relatively fresh index at EC2.
=-=119 - Fri Jan  8 11:35:32 PST 2010

Super slow on EC2. Culprit: Scanning workspace for candidates. time:keep needs
to be speeded up.
=-=122 - Sat Jan  9 15:08:14 PST 2010
After considering trees and priority queues, settled on a skiplist data
structure for fast top-n and search/insert/delete operations. Starting to
build one in arc.
=-=125 - Sun Jan 10 01:13:06 PST 2010
More elegant skip list phrasing. Onward.
=-=126 - Sun Jan 10 12:24:41 PST 2010

Intermittent bug.
current stack:
  random-level not getting overridden
  isolate reproducibly failing test
  was insert working before introducing scan?
  fix insert regression after introducing scan
  refactor out fit-into

Ack, scoped-extend will need more work. I need to save the value and yet
shadow. Ignore it for now.
=-=127 - Sun Jan 10 12:55:08 PST 2010
test fails when we insert at height 0.
=-=128 - Sun Jan 10 13:09:04 PST 2010
Ack, weird typos. Fixed with some divide and conquer from rev 125 onward.
One drawback of loop: the three cases are hard to see and if there's a fourth
like here you can run around chasing your tail.
=-=130 - Sun Jan 10 13:40:26 PST 2010
Better indentation can help.
=-=131 - Sun Jan 10 13:41:28 PST 2010
Cleanup. Back to refactoring fit-into.
=-=132 - Sun Jan 10 13:52:01 PST 2010
scoped-extend fixed!
=-=133 - Sun Jan 10 14:07:21 PST 2010
Updated skip list test to use scoped-extend.
=-=134 - Sun Jan 10 14:21:39 PST 2010
Cleanup.
=-=135 - Sun Jan 10 14:30:05 PST 2010
Wow, how was it working? base-0 indexing, base-1 indexing, it was a mess.
Anyway, find almost done. Final test still failing.
=-=136 - Sun Jan 10 16:04:09 PST 2010
Whoa, and it's again non-deterministic.
=-=137 - Sun Jan 10 16:05:21 PST 2010
Agh, random-level sometimes returns nil.
This was really hard to debug until I just started staring at its output.
Combination of non-manifestation for short runs + non-determinism at 500-iter
run + not being able to print out nodes.
=-=138 - Sun Jan 10 16:36:08 PST 2010
