Test 7 isn't consistent.
=-=2 - Fri Dec  4 18:17:19 PST 2009

Toy examples done. url -> related docs.
Data structures now starting to take shape.

Tests are ugly, code interleaved with data.
We can use more indexes.
Decouple the index like in SQL, so the same code runs faster if the index
exists.
=-=4 - Fri Dec  4 19:14:31 PST 2009

Finished building the index. gen-docs works.
=-=5 - Sat Dec  5 09:47:15 PST 2009
Added agg3 ui to it. Messy that I've added stations to the flat-history model.
  Form to create new station.
  Choose between stations, each station gets its own read-list.
=-=6 - Mon Dec  7 13:22:11 PST 2009

Importing agg3 crawl pipeline. Next step: merge properly.

Vision: crawl a universal set of feeds. Don't wait for entire crawl to import
crawled feeds. Track per-user feeds and feed priorities in userinfo*. Make
agg3 just another station for users who import feeds. Push station selection
to a new screen; add new station form to the left panel when reading. Track
history by station.

Later: screens to manage feeds. Stations for importing email, other data
sources, etc. Discovering new feeds during crawl.
=-=7 - Tue Dec  8 12:06:08 PST 2009

crawl and htmlclean now communicate by fifo.
But it's currently blocking. So htmlclean blocks until input, then just reads
the first input and goes back to waiting. Meanwhile if I add a delay to
htmlclean it blocks crawl instead.
=-=8 - Tue Dec  8 14:11:15 PST 2009
If we stick with the blocking model we need to start the pipeline in reverse
order, from consumer to producer of each fifo.

If any stage dies, all other stages will block.

Will we lose stuff in fifos if we kill arc? Periodically look at files under
urls/
=-=9 - Tue Dec  8 15:06:09 PST 2009
Redefine defscan to run in separate threads, not a single thread.
Also some reorg.
=-=10 - Tue Dec  8 18:16:09 PST 2009

3 Crawl errors fixed.
=-=11 - Tue Dec  8 19:34:06 PST 2009

Instead of printing progress for background threads, maintain a circular
buffer of messages for each.
Not persistent for now.
=-=12 - Tue Dec  8 22:34:02 PST 2009

Focusing on UI.
Yesterday's problem: we want to scan read-list for both gen-docs and rendering
history.
=-=14 - Tue Dec  8 22:48:22 PST 2009

Ok, partial matches now working. Takes too long, though. Do all the work in
one pass. Every page load should do just one pass through docinfo*.
=-=15 - Tue Dec  8 23:24:59 PST 2009
Single pass for site-docs and feed-docs takes test runtime down from 72s to
42s for 13650 items in docinfo. But it's still too much.
=-=16 - Tue Dec  8 23:54:18 PST 2009
All that time is being spent on downcase!
Just add downcase versions of all metadata.
Or cache downcase separately.
=-=17 - Wed Dec  9 00:00:57 PST 2009
Yep, cached downcase and got to within 3x of non-downcase version.
=-=18 - Wed Dec  9 00:04:45 PST 2009

Time to start indexing. It's working, but dies every now and then. I think
it's dying when the pipe breaks.
=-=19 - Wed Dec  9 00:35:19 PST 2009
Ok, found the core dump in keywords.cc - negative index.
=-=21 - Thu Dec 10 00:44:08 PST 2009
Cleanup.
=-=22 - Thu Dec 10 00:46:41 PST 2009

Back to the UI. Refactoring index.arc to always take a user arg.
gen-docs doesn't like docs as arguments. I need to test-drive this..
=-=23 - Fri Dec 11 04:55:14 PST 2009
Done. Rebuilding the index.
=-=24 - Fri Dec 11 08:10:24 PST 2009

Lots of reorg, getting tests to pass.
Framework for gen-docs:
  generate candidates using doc-filters* and misc-filters*
  constraints to filter candidates
  score remaining candidates
=-=27 - Fri Dec 11 22:41:22 PST 2009

Trying to redo transparent persistence.
  Avoid unnecessary writes based on palsecam's idea.
  Write to new files so we have backups, and to eliminate any chance of data loss.
Doesn't work yet. I just realized save-registry needs to store references to
variables, not names.
Which means if I assign to a persistent variable I will lose persistence on it.
=-=30 - Sun Dec 13 19:53:37 PST 2009
Ok, save-registry now indexes by reference. But still not working. What's
going on?

Two bugs:
  a) (hash key) searches by value, even if what is stored in the hash is a
  reference. What's more it's searching by value at the time of insertion.
  Weird.
  b) buffered-exec isn't wiping when it should.
=-=31 - Sun Dec 13 20:43:03 PST 2009
Ah, it's a *hash* table. It's storing by reference but the hash is computed by
value.
  http://arclanguage.org/item?id=10984
It just shouldn't store by reference. That makes it too confusing.

Got the new transparent persistence working.
=-=32 - Mon Dec 14 01:23:05 PST 2009
Bugfix: snapshots were never being loaded.
=-= - Mon Dec 14 11:30:12 PST 2009

Getting readwarp up on AWS.
After all that testing turns out I never tested the metadata scan. It was
emitting strings with quotes escaped. Fixed.
=-=33 - Wed Dec 16 01:30:36 PST 2009
More bugfixing.
=-=36 - Thu Dec 17 17:18:00 PST 2009
Compute affinity graph by feed rather than url.

But it was taking too long; dhash wasn't working right. Ah, I never did
implement the nilcache idea to avoid recomputation.
Bring back old state.arc tests as well.
=-=37 - Thu Dec 17 19:55:41 PST 2009
Still struggling to compute feed affinity graph.
It's too slow. Let's switch to shell pipes. Dev speed includes performance
when experiments are this intensive and iterations this frequent.
=-=39 - Fri Dec 18 21:21:02 PST 2009

New python script to try normalizing overlap by keyword between feeds - each
keyword distributes 1/n to n*n feed connections.
We're seeing some quality. Krugman's blog is kinda well-connected to financial
blogs or blogs with kinda financial content.

Next steps:
  a signal for article-article overlap to help get at financial posts within
  say larry cheng's feed
  improve html cleaning to remove spurious overlap

Let's see if we can get by without changing keywords algo.
=-=41 - Sat Dec 19 15:29:31 PST 2009

Focusing on html cleaning now. First step: workflow to add tests to a corpus.
=-=42 - Sun Dec 20 15:25:27 PST 2009
Test script up and running.
=-=46 - Sun Dec 20 19:42:33 PST 2009
Added failing test cases by searching for commonly-occurring sets of keywords.
Just make one test case from each such set, that gives us 53 failing tests.
Ok, we've now got our work cut out for us.
=-=49 - Mon Dec 21 01:01:44 PST 2009

I need to add hints from feed descriptions. Step 1: crawl feeds to save
descriptions.
=-=50 - Tue Dec 22 12:23:03 PST 2009
Step 2: use the deschint: if it exists return the highest-scoring node that
contains the hint as a substring.

Unicode errors; I'm going over this tutorial:
  http://docs.python.org/howto/unicode.html
=-=51 - Tue Dec 22 13:55:41 PST 2009
=-=52 - Tue Dec 22 20:16:06 PST 2009
Turns out sorting by score then searching for a superset of deschint isn't
working.
=-=53 - Wed Dec 23 00:12:14 PST 2009
Fixed. 12 more tests passing.
=-=54 - Wed Dec 23 00:28:47 PST 2009
Evaluating the html cleaning process. We have 4 kinds of errors:
  Fixating on common content, either subtitles or sidebar
  Picking a comment instead of the post, usually when there's lots of comments
    slashdot, etc.
  Picking too much
  Picking too little
We've been under-estimating how well deschint does because these failures
aren't in their feeds anymore. Let's manually add hints, then try it on live
data.
=-=57 - Wed Dec 23 12:50:21 PST 2009
Hints manually added; 23 more tests pass, 31 still failing.
=-=59 - Wed Dec 23 13:50:59 PST 2009
Focussing on tweets. Why is so little matching?
=-=60 - Wed Dec 23 14:18:07 PST 2009
difflib limitation. Switched to http://code.google.com/p/google-diff-match-patch
Now we're down to 10 failing tests, but with two caveats:
  a) The new code is *much* slower. 150 tests took 34 minutes, which used to
  take ~1-2 minutes.
  b) We're probably under-counting failures because too-loose failures no
  longer get detected.
=-=61 - Wed Dec 23 15:55:08 PST 2009
Simple dilution metric to identify failing tests. 0.6 seems like a reasonable
boundary, but we're gonna occasionally get it wrong.
It's only for identifying failing tests, though. Let's focus on making them
pass more unequivocally.
=-=62 - Wed Dec 23 16:26:47 PST 2009
=-=63 - Wed Dec 23 17:55:01 PST 2009
Debugged the dilution metric. 50 of yesterday's tests are now reclassified as
failing, but I'm finally certain I'm not over-counting.

This took too long. I'd introduced a bug in fuzzymatch, then spent all day
staring at fuzzycheck.
=-=65 - Thu Dec 24 11:30:08 PST 2009
Cleanup.
=-=66 - Thu Dec 24 12:02:12 PST 2009
4 regressions compared to rev 57.
=-=68 - Thu Dec 24 14:38:07 PST 2009
Lost momentum yday thinking diff-match-patch too had issues as a difflib.

After adding a couple of test cases today I realize the problem isn't the diff
algo, but beautifulSoup. When the html breaks it inserts close tags in the
wrong place.
=-=69 - Fri Dec 25 20:59:34 PST 2009
No, even the html parsing is fine. So how are we getting close tags in the
wrong place?
=-=70 - Fri Dec 25 21:09:51 PST 2009
Ah, it's the substitution of <br> pairs for <p>'s. Then the <p> within the
table confuses BeautifulSoup.
=-=71 - Fri Dec 25 21:16:42 PST 2009
  [Accidentally committed htmlclean.py@60. Back to 68.
  =-=72 - Fri Dec 25 21:25:12 PST 2009]
It's a simple fix! Replace with <p>, not </p><p>. The close tag causes grief.
=-=73 - Fri Dec 25 21:30:24 PST 2009
Ok, convinced myself I don't really have regressions, the new failures are
because of tighter checks.
=-=77 - Sat Dec 26 12:35:32 PST 2009
=-=79 - Sun Dec 27 10:33:47 PST 2009

Back to arc. Loose html cleaning is ok for now - we'll at least get the
content of the article. Getting the whole html is prob bad, but let's see how
far we get with what we have.

New ds: feed-list*
Resisting the urge to create a fun defrep macro.
=-=81 - Mon Dec 28 21:42:49 PST 2009
Clean out old implementation. Let's just get keyword->seed feed working for
starters. Typing in 'cnn' should show a story from cnn.com
=-=82 - Mon Dec 28 21:51:38 PST 2009

Update crawl to record some feed metadata.
No author, sadly.
=-=83 - Tue Dec 29 18:15:04 PST 2009
Ah, just save feed description.
=-=86 - Wed Dec 30 11:52:59 PST 2009
First cut of kwd->feed. Too slow.
=-=89 - Thu Dec 31 04:36:33 PST 2009
Indexing feedinfo now. kwd-feeds can now help locate seed feeds.
=-=90 - Fri Jan  1 18:15:12 PST 2010
kwd-feeds now done.
scan-doc-dir: Finding docs that aren't in docinfo.

Also some new utils.
Start creating data structures more willy-nilly. We're almost there. Build,
then refactor.
=-=91 - Sun Jan  3 20:08:08 PST 2010
scan-doc-dir ended up costing me a whole day.
When I work without deliberation I can make boneheaded decisions like this.
And now snapshots.docinfo takes over 15 minutes to load.
=-=92 - Mon Jan  4 11:26:01 PST 2010
feed-affinity graph: Translate feedgraph.py into arc.
=-=93 - Mon Jan  4 17:29:39 PST 2010
feed-affinity graph implemented, not yet operationalized so I don't know how
to incrementally update it.
Too many pieces of the pipeline are having trouble scaling. I need to figure
out why.
  Start gc'ing documents.
=-=95 - Mon Jan  4 23:49:30 PST 2010
Ok, we were out of disk, that explains the slow initialization.
feed-affinity graph is easy to incrementally update. After the initial run
start calling update-normalized-keyword-clusters for each feed as it rolls in.
=-=96 - Tue Jan  5 09:38:02 PST 2010
shadow macro: dynamic binding so I can run tests on index functions without
having the fixtures clobber my shite.
We'll still lose changes while the tests run, though.
=-=97 - Tue Jan  5 12:53:30 PST 2010
another helper: shadow all persistent variables.
=-=98 - Tue Jan  5 14:23:55 PST 2010
index.arc.t will now run properly without touching real indexes.
Its tests still fail though.
=-=99 - Tue Jan  5 14:34:50 PST 2010

Workspace. Test driving several primitives.
=-=102 - Tue Jan  5 18:27:31 PST 2010
Done test-driving propagate primitives. This shouldn't have been so hard.
=-=104 - Wed Jan  6 00:04:08 PST 2010
Playing around with propagate. Added reinforce to boost candidates without
creating new ones.
Several sources of error in updating feeds. Moving back to the backend.
=-=106 - Wed Jan  6 12:21:09 PST 2010
Some tune-up.
Spent too long rebuilding the data structures. Again, shouldn't have been so
hard.
=-=107 - Wed Jan  6 14:26:37 PST 2010
Ok, incremental updates to data structures now working.
=-=109 - Wed Jan  6 15:24:45 PST 2010
Putting all the pieces together. Propagate working, but we just keep
propagating docs to keywords. We need to pick some other items each time to
propagate to more docs.
=-=113 - Thu Jan  7 18:54:43 PST 2010
Workspace entries now know their age in iters. Iter = up-vote.
First-cut of prune.
Code is functional, passes all tests, responsive. We still never leave the
seed feeds.
=-=115 - Fri Jan  8 00:17:02 PST 2010
Add only unread docs to workspace.
=-=116 - Fri Jan  8 00:36:55 PST 2010
Propagate-to-doc working, we're starting to see new feeds gradually pop up.
=-=117 - Fri Jan  8 10:50:20 PST 2010
Diversity - no more consecutive stories from a feed.
=-=118 - Fri Jan  8 11:29:28 PST 2010
Some bugfixes as I move past my 'krugman' test case to a 'burrito justice'
station.
Time to get on the relatively fresh index at EC2.
=-=119 - Fri Jan  8 11:35:32 PST 2010

Super slow on EC2. Culprit: Scanning workspace for candidates. time:keep needs
to be speeded up.
=-=122 - Sat Jan  9 15:08:14 PST 2010
After considering trees and priority queues, settled on a skiplist data
structure for fast top-n and search/insert/delete operations. Starting to
build one in arc.
=-=125 - Sun Jan 10 01:13:06 PST 2010
More elegant skip list phrasing. Onward.
=-=126 - Sun Jan 10 12:24:41 PST 2010

Intermittent bug.
current stack:
  random-level not getting overridden
  isolate reproducibly failing test
  was insert working before introducing scan?
  fix insert regression after introducing scan
  refactor out fit-into

Ack, scoped-extend will need more work. I need to save the value and yet
shadow. Ignore it for now.
=-=127 - Sun Jan 10 12:55:08 PST 2010
test fails when we insert at height 0.
=-=128 - Sun Jan 10 13:09:04 PST 2010
Ack, weird typos. Fixed with some divide and conquer from rev 125 onward.
One drawback of loop: the three cases are hard to see and if there's a fourth
like here you can run around chasing your tail.
=-=130 - Sun Jan 10 13:40:26 PST 2010
Better indentation can help.
=-=131 - Sun Jan 10 13:41:28 PST 2010
Cleanup. Back to refactoring fit-into.
=-=132 - Sun Jan 10 13:52:01 PST 2010
scoped-extend fixed!
=-=133 - Sun Jan 10 14:07:21 PST 2010
Updated skip list test to use scoped-extend.
=-=134 - Sun Jan 10 14:21:39 PST 2010
Cleanup.
=-=135 - Sun Jan 10 14:30:05 PST 2010
Wow, how was it working? base-0 indexing, base-1 indexing, it was a mess.
Anyway, find almost done. Final test still failing.
=-=136 - Sun Jan 10 16:04:09 PST 2010
Whoa, and it's again non-deterministic.
=-=137 - Sun Jan 10 16:05:21 PST 2010
Agh, random-level sometimes returns nil.
This was really hard to debug until I just started staring at its output.
Combination of non-manifestation for short runs + non-determinism at 500-iter
run + not being able to print out nodes.
=-=138 - Sun Jan 10 16:36:08 PST 2010
False alarm: I'd confused myself in trying to create a track for random-level.
The real bug was one last vestige (hopefully) of base-0/base-1 confusion.
=-=139 - Sun Jan 10 16:54:46 PST 2010
Cleanup.
=-=140 - Sun Jan 10 17:10:07 PST 2010
redef macro to disable redefinition warnings.
=-=141 - Sun Jan 10 17:16:55 PST 2010
looplet -> letloop. Better indicates that loop is within a new scope rather
than vice versa. Also avoids association with piglet, etc.
=-=142 - Sun Jan 10 17:21:56 PST 2010
Use redef in before/after-exec.
=-=143 - Sun Jan 10 17:28:29 PST 2010
Performance test done, skip list is working fine. Disabled by default since
it's interactive.
I have a version to pick random numbers, but it won't be very
well-distributed.
=-=145 - Sun Jan 10 18:52:57 PST 2010
Ok, I can enable it if I create a more dense list.
=-=146 - Sun Jan 10 18:58:50 PST 2010

Starting on transformer function for skip lists.
=-=148 - Sun Jan 10 19:22:03 PST 2010
First test of insert and find now working.
Code's looking ugly now, especially the var nv in find-sl.
=-=149 - Sun Jan 10 19:35:33 PST 2010
Hmm, another set of tests seem to show all in order.
=-=150 - Sun Jan 10 23:12:10 PST 2010
Cleanup.
=-=151 - Sun Jan 10 23:15:33 PST 2010
Delete.
One failing test case: can't find multiple entries with identical transformer
functions. Not an issue before we added transformer functions.
=-=152 - Mon Jan 11 00:23:49 PST 2010
Fixed.
Entire final page of skiplist methods is now super-ugly. find, delete, scan2.
=-=153 - Mon Jan 11 00:36:48 PST 2010
Mon Jan 11 00:49:38 PST 2010
Still one issues to be ironed out in skip lists: when to wade sequentially
through entries transforming to the same metric. I run into an infinite loop
every so often, even though there's now 5 conditions on it.
Mon Jan 11 11:04:43 PST 2010
Scanning ahead on level 0 violates a pre-condition: that in scan2(sl nd v l)
nd!next has at least l+1 elements. Scanning ahead by 1 can leave you with an
element of shorter height.
We shouldn't be doing this except after the final scan.
=-=154 - Mon Jan 11 11:06:46 PST 2010
Intermediate cleanup. New test cases coming up.
=-=155 - Mon Jan 11 11:31:24 PST 2010
New fixture, and a couple of tests with it. Already the code looks cleaner.
=-=156 - Mon Jan 11 12:28:53 PST 2010
Other tests easily pass.
=-=157 - Mon Jan 11 12:40:51 PST 2010
Cleanup. Zoomed back out to the whole project. All tests pass.
=-=158 - Mon Jan 11 12:58:15 PST 2010

Trying briefly to make the new-snapshot-name test more consistent.
But for some reason ,(seconds) doesn't get over-ridden.
=-=159 - Mon Jan 11 13:43:40 PST 2010
It's because anytime you invoke new-snapshot-name from a function, it gets
macro-expanded in place.
Let's just get rid of that test, it's not worth the trouble.
=-=160 - Mon Jan 11 13:47:31 PST 2010

Ok, start using skip lists in workspace. Pre-cleanup.
=-=161 - Mon Jan 11 14:17:41 PST 2010
Integrated into workspace; now propagate seems slow, with all those
insert-sl's.
=-=163 - Mon Jan 11 18:12:15 PST 2010
If I hit C-c while tests are running I get a "could not shadow" message with
a humongous, uninterruptable printout of the large data structures. Fixed.
=-=165 - Mon Jan 11 21:27:59 PST 2010
index tests passing. But I need to turn off defrep's to avoid interfering with
tests. Still holding out before using aw's proper dynamic variables.
=-=166 - Mon Jan 11 22:08:00 PST 2010
Ah, insert-sl is inefficient! Each level starts from the start of the list, so
the lowest level is always treating it as a plain list.
Hopefully this is the reason propagate is slow.
=-=168 - Mon Jan 11 22:40:12 PST 2010
Fixed.
=-=169 - Mon Jan 11 22:41:07 PST 2010

New bug: app suddenly seizes up inside insert-sl every so often.
It's not GC. It really is where the prints say it is (the artificial stack
trace confirms it's always stalled in f1 or f2). And once it gets there any
assignment stalls it, not writes to node!next. An issue with atomic?
=-=170 - Tue Jan 12 10:45:25 PST 2010
We're definitely not running out of thread-cells or semaphores since only one
of each is ever created (instrumented arc).
=-=171 - Tue Jan 12 11:24:17 PST 2010
Ah, a glimmer. Things work when we stop modifying sref to autosave.
=-=172 - Tue Jan 12 12:03:54 PST 2010
It's not an infinite loop in trying to buffered-exec. In fact we never even
trigger buffered-exec.
It's not really happening with the modified sref, or at least not as far as I
can see.
=-=173 - Tue Jan 12 12:19:07 PST 2010
And yet, if we disable buffered-exec entirely the problem goes away.
=-=174 - Tue Jan 12 12:20:36 PST 2010
Waiting for atomic's semaphore with the other thread?
=-=175 - Tue Jan 12 12:23:03 PST 2010
Argh, it's dying when the first buffered-exec triggers, so we can't currently
run for longer than 10s!
=-=176 - Tue Jan 12 12:25:59 PST 2010
Ok, we're unable to write userinfo*. Nothing to do with skiplists or index at
all.
=-=177 - Tue Jan 12 12:28:26 PST 2010
Cleanup. Of course we won't be able to write userinfo* now what we have all
these pointers all over the place. I should have realized when I deleted all
those userinfo*.*.tmp files a couple of hours ago.
=-=178 - Tue Jan 12 12:39:07 PST 2010
Just ignore saving userinfo* for now. For the demos this week let's just show
a stateless version. Now focus on speed, in the UI and in the crawl/clean
pipeline.
=-=179 - Tue Jan 12 15:05:50 PST 2010

Ok, benchmarking is now up. Bottleneck now propagate, not next-doc. So far, so
good.
=-=180 - Tue Jan 12 16:06:42 PST 2010
Memoizing metric in skiplist gives us 3-3.5x speedup. First propagate now
takes 20s rather than 70s. Still too long.
=-=182 - Tue Jan 12 17:17:53 PST 2010
We're doing 760k skiplist traversals in 1350 propagates. 15ms/prop, 38
travs/ms.
=-=183 - Tue Jan 12 17:53:30 PST 2010
Is the problem that next pointers are in a list? Preliminary experiments
indicate that random access in lists of size 30 is as cheap as in a table. By
the time the list grows to 750 elements there's a factor of 5 difference.
=-=184 - Tue Jan 12 18:05:49 PST 2010
Confirmed that the inner loop is scan (and not scan-handling-ties). 20s out of
25 are spent within it.
=-=185 - Tue Jan 12 18:12:03 PST 2010

First few iterations on laptop:
  == A
  time: 2 msec.
  "marking read " "http___krugman_blogs_nytimes_com_2009_11_09_finance_mythbusting_third_world_edition_" 
  propagating from http___krugman_blogs_nytimes_com_2009_11_09_finance_mythbusting_third_world_edition_ 25
  after prop: 808
  time: 7445 msec.
  99632 travs in 820 propagates
  == B
  time: 10 msec.
  "marking read " "http___yelnick_typepad_com_technik_2005_03_venture_overhan_html" 
  propagating from http___yelnick_typepad_com_technik_2005_03_venture_overhan_html 808
  after prop: 1945
  time: 27867 msec.
  745141 travs in 1349 propagates
  == C
  time: 1 msec.
  "marking read " "http___karthik82_com__page_doom_mode_reviews_id_12" 
  propagating from http___karthik82_com__page_doom_mode_reviews_id_12 1945
  after prop: 2171
  time: 34380 msec.
  == D
  time: 1 msec.
  "marking read " "http___yelnick_typepad_com_technik_2003_09_microsoft_blaze_html" 
  propagating from http___yelnick_typepad_com_technik_2003_09_microsoft_blaze_html 2148
  after prop: 2478
  time: 14625 msec.
  == E
  time: 15 msec.
  "marking read " "http___bnoopy_typepad_com_bnoopy_2004_10_moons_over_my_h_html" 
  propagating from http___bnoopy_typepad_com_bnoopy_2004_10_moons_over_my_h_html 1837
  after prop: 3532
  time: 95589 msec.

On EC2, propagating from 253 nodes, iter B takes over 10 minutes.
=-=190 - Wed Jan 13 11:49:47 PST 2010
Without doc-keywords-docs it's blazing.
=-=191 - Wed Jan 13 12:28:41 PST 2010
Evaluation before showing H&F meetup. Major issues:
1. It's still slow. timeout-exec isn't useable; fails to relinquish atomic
2. It's often ping-ponging between two feeds
  a) Downvotes don't penalize feed
  b) feed-affinity* graph only contains 99 feeds out of 1500
=-=194 - Wed Jan 13 17:28:11 PST 2010

Updating utils after code review:
  http://arclanguage.org/item?id=11129
In particular, it's useful that the way arc does destructuring eliminates the
major use case for zipmax.
=-=195 - Thu Jan 14 00:03:18 PST 2010

After fixing the kill-thread bug in arc, timeout-exec is working well.
Still kinda sluggish; we're seeing times of upto 30s, but this should suffice.
=-=197 - Thu Jan 14 13:27:09 PST 2010

Now focus on htmlclean. First step: revert to difflib. Suddenly it's much
faster. 33 failed test cases, but I'm now not convinced we're detecting
failures correctly.
=-=199 - Thu Jan 14 21:34:24 PST 2010
If we don't have faith in the metric, let's at least fall back to a metric we
do have faith in.
=-=200 - Thu Jan 14 21:41:50 PST 2010
Deleting pass 2. 4 more failures, but 4 extra certain successes, and tests
take 25% less time to run. So much for that.
=-=201 - Thu Jan 14 22:08:17 PST 2010
Degrade gracefully to just the feed description when you can't find a
candidate.
Why do I still have failing tests. Agh, let's try it out for reals.
=-=202 - Thu Jan 14 22:19:58 PST 2010
Don't show empty descriptions.
=-=203 - Thu Jan 14 22:38:56 PST 2010
Fresh urls. Cleanup.
=-=204 - Thu Jan 14 22:54:42 PST 2010

Back to front-end while the crawl runs.
Seth Cohen's suggestion yday: show story date.
=-=205 - Thu Jan 14 23:17:46 PST 2010
UI: new buttons with tool tips. Hooked up to nothing yet.
=-=206 - Fri Jan 15 00:25:29 PST 2010
Star for feed done.

- from plan
Preferred feeds ds by station. table: feed -> (manual weight (0-n), inferred weight (-1 to 1))
Showlist ds: Construct 5 stories at a time
Populating showlist
  Choose 1 lit doc in worklist
  Choose most recent story from upto 4 separate preferred feeds, avoiding the last 5
  Fill remainder with most recent story from random feeds by affinity, avoiding last 5
  Fill remainder with most recent story from random feeds, avoiding last 5 and unpreferred feeds
  Fill remainder with most recent story from random unpreferred feeds, avoiding last 5
  Fill remainder with most recent story from random feeds

mark-read: outcome 1-4
  4: preferred feed, propagate doc
  3: preferred feed after 5 3s, propagate doc
  2: do nothing
  1:
     manually preferred feed: disable prefer after 5 1s
     preferred feed: disable after 2 1s
     not preferred: unprefer
=-=207 - Fri Jan 15 14:07:21 PST 2010
Step 1: showlist data structure
=-=208 - Fri Jan 15 14:52:48 PST 2010
Step 2: preferred feeds, make it a table of properties rather than a simple
list
=-=209 - Fri Jan 15 15:55:55 PST 2010
mark-read => preferred feeds
=-=211 - Fri Jan 15 18:08:24 PST 2010

History icons fixed.
Clicking on things in the history brings them forward in this session, but not
in a persistent way. That seems reasonable.
=-=212 - Fri Jan 15 18:22:39 PST 2010

Populating showlist.
No change in behavior yet, but new structure is in place.
=-=213 - Fri Jan 15 18:47:57 PST 2010
Cranked it all out in one fell swoop. Not test-driven, not much testing. Now
let's play with it. 3 more hours before bed and tomorrow's reverse job fair.
=-=214 - Fri Jan 15 20:30:53 PST 2010
Unpreferred feeds weren't going away. Fixed.
3 other obvious issues:
1 feed affinity graph is broken. can't fix today. hopefully the new crawl will
  make it better.
2 scanning by affinity inserts dup feeds
3 new batch doesn't dedup against previous batch of 5
=-=215 - Fri Jan 15 20:47:45 PST 2010

Ack, shoulda enabled feed-affinity computations before restarting the crawl
yday.
=-=216 - Fri Jan 15 20:52:35 PST 2010

Issue 2 fixed. No more dups within a batch.
=-=217 - Fri Jan 15 20:56:13 PST 2010
Issue 3 fixed.
=-=218 - Fri Jan 15 21:12:11 PST 2010
Cleanup.
=-=219 - Fri Jan 15 21:15:06 PST 2010

Reset userinfo from online.
=-=222 - Sat Jan 16 07:45:56 PST 2010
Boundary condition: make the first story relevant and non-random if possible.
=-=223 - Sat Jan 16 07:48:17 PST 2010
New pass: pick feeds from the same group. Things looking much better.
Ok, work on speeding up EC2 now.
=-=225 - Sat Jan 16 08:17:10 PST 2010

mzscheme seems more finicky about load order on EC2. Fixed.
=-=226 - Sat Jan 16 08:40:47 PST 2010

Don't wait to the end of crawl to emit feedinfo.
=-=229 - Sat Jan 16 09:13:50 PST 2010

Logo idea after shdh.
=-=232 - Sat Jan 16 17:02:27 PST 2010
Front-page copy.
=-=233 - Sat Jan 16 17:12:42 PST 2010

Better feedinfo handling: save intermediate files, but don't delete the full
file until you have a complete replacement. In arc, gracefully read the best
version you can find.
=-=234 - Sat Jan 16 20:02:37 PST 2010

Logo: specify helvetica
Tried italic, that's pretty decent as well.
=-=235 - Sun Jan 17 19:51:24 PST 2010

A couple of bugfixes in update-feeds. We should now never lack for a story to
display, no matter how crappy.
=-=239 - Mon Jan 18 14:36:43 PST 2010

Bug in wait. I wasn't waiting for feed data structures to get initialized, and
that was messing things up.
But initializing data structures was taking forever in the presence of other
threads. The hypothesis was that multiple threads were thrashing on the atomic
semaphore. But even with that hypothesis the problem seemed insoluble..

Until I enclosed the function in an atomic. That's the second time (after
commit 197) that trick has bailed me out.
=-=241 - Tue Jan 19 20:33:31 PST 2010
Another atomic in the UI.
We're still seeing some timeouts, but not nearly so much. Inter-story delay is
pretty significant (10s of seconds). I'm freezing instrumentation to help
track why the timeout happens.
=-=244 - Tue Jan 19 21:53:53 PST 2010

Reloading index.arc was killing the repl.
=-=245 - Tue Jan 19 22:45:42 PST 2010

Try to ensure the first story on a station doesn't surprise the user.
=-=246 - Tue Jan 19 23:09:17 PST 2010

Trying to support partial urls, like cnn when the desc contains only cnn.com.
Or news.ycombinator.
=-=247 - Wed Jan 20 01:56:05 PST 2010
Fixed. Only include url in split-urls inside feed-keyword, not always.
=-=248 - Wed Jan 20 02:03:52 PST 2010

More tweaks to atomic: we only want the first iteration of defrep to be atomic
when the main thread may be waiting on it.
=-=249 - Wed Jan 20 12:38:23 PST 2010

For now let's just eliminate all our hacky atomics, disable the indexing
thread, and stabilize things on ec2 production.
Then I'm going to start investigating performance more thoroughly with
vector-set-performance-stats! (http://arclanguage.org/item?id=11177)
=-=250 - Thu Jan 21 10:10:38 PST 2010
doc-affinity takes forever to build. Ordering update-feeds ahead of it.
Still takes forever to get to a prompt. Disabling doc-affinity.
mzscheme keeps segfaulting now. Giving up, undo commit 249.
=-=251 - Thu Jan 21 11:30:55 PST 2010

Ah, the number of thread switches in UI thread goes up by 8x from 200 to 1600
when I enable the back-end. And it's all because of computations to update
feed-affinity, which I haven't really been using anyway. And doc-affinity we
already know isn't even every full computed.
Get rid of all that over-engineered cruft and the server is now looking very
promising.
=-=254 - Thu Jan 21 15:28:20 PST 2010

Suddenly save-snapshot isn't working.
=-=255 - Thu Jan 21 16:25:12 PST 2010
Bugfix to fwritefile: sometimes the file isn't available on the file system
before we try to rename it.
=-=256 - Thu Jan 21 18:13:34 PST 2010

Bringing back commit 249, defrep is now as it should be.
=-=257 - Thu Jan 21 18:26:02 PST 2010
Cleanup. Tests green again.
=-=258 - Thu Jan 21 18:35:20 PST 2010
Still more cleanup. All calls to keywords now gone.
=-=259 - Thu Jan 21 18:57:39 PST 2010

htmlclean: if the outermost node is a td, make it a div. Interferes with our
rendering.
=-=261 - Fri Jan 22 00:54:36 PST 2010

More cleanup, some refactoring.
=-=264 - Sat Jan 23 13:10:17 PST 2010

Monitoring logs, step 1: queries people type in.
=-=265 - Sat Jan 23 18:59:20 PST 2010

Done importing sites. blogs some other day.
When I build feed discovery I'm going to put requested feeds in a cordoned off
area until they're activated by somebody explicitly asking for them.
=-=266 - Sat Jan 23 19:59:05 PST 2010

New refactoring: inittab.
But I need it to evaluate keys as well.
=-=272 - Sun Jan 24 11:02:32 PST 2010
The obvious way doesn't work - just make it (table eval.k):
  Error: "reference to undefined identifier: _k"
  arc> (with (a nil x 3) (macex1 '(inittab a x (+ 3 1))))
  (do (or= a (table)) (each (k v) (pair (quote (x (+ 3 1)))) (or= (a eval.k) eval.v)) a)
  arc> (let x 3 (eval 'x))
  Error: "reference to undefined identifier: _x"
Should eval recognize let bindings? It doesn't work in mzscheme either.

In any case, there is a solution: draw a fresh boundary between function and
macro to enable evaluation.
Inspired by fill-table after reading http://arclanguage.org/item?id=456
via* arcforum searchyc: obj
But it's not perfect. If I want init-table to take an explicit second list arg
like fill-table I don't know how to keep inittab working.
I see what Alan Kay meant now; it feels kinda hackish to influence evaluation
by function boundary, use of @, etc.
=-=273 - Sun Jan 24 11:43:41 PST 2010
http://arclanguage.org/item?id=11187
=-=277 - Sun Jan 24 13:59:57 PST 2010

Tell people when you're falling back to random. Test query: "bored cricket
crazy indians"
=-=282 - Mon Jan 25 11:55:57 PST 2010

Daniel Markham's idea: a news ticker.
js from http://www.mioplanet.com/rsc/newsticker_javascript.htm
"free for personal and commercial use"
=-=287 - Mon Jan 25 17:32:22 PST 2010
Hack it to update ticker contents from a second div if they exist.
=-=288 - Mon Jan 25 17:33:49 PST 2010
Basic ticker now working inside arc.
=-=289 - Mon Jan 25 20:24:00 PST 2010
Cleanup. The ticker js requires width to be in the style tag, but the rest can
be in the css file.
=-=290 - Mon Jan 25 20:35:39 PST 2010
Ticker js now showing live feeds.
Periodically updating the ticker isn't working yet.
Also, we're seeing too little at once, it's moving too sluggishly. There's no
sense of a menu.
=-=291 - Mon Jan 25 21:32:24 PST 2010
Ticker js/css bugs fixed.
=-=292 - Mon Jan 25 21:44:28 PST 2010
Smaller font-size helps. And it's now starting with a populated ticker.
There's too few options, and that's partly because many feeds are too long. I
could try trimming and whatnot.. but what if I make each option stand
vertically, and trim past some height?
=-=293 - Mon Jan 25 21:50:18 PST 2010
To make it cross-browser I'd need to get into SVG:
  http://bytes.com/topic/javascript/answers/721811-solution-display-text-rotated-90-vertically-firefox-css
Ok, give up.
=-=294 - Mon Jan 25 21:55:12 PST 2010
Just trim the titles. Verified it's working on Safari, Firefox, Chrome on Mac.
=-=295 - Mon Jan 25 22:10:52 PST 2010
Copy tweaks, some cleanup.
=-=296 - Mon Jan 25 23:15:43 PST 2010

Always first show first item from requested feed before branching out.
=-=297 - Tue Jan 26 00:42:54 PST 2010

Feedback form.
=-=299 - Tue Jan 26 10:17:40 PST 2010
Make feedback form work on not just the first load of a station. Requires
threading station everywhere, yuck.
=-=300 - Tue Jan 26 10:46:21 PST 2010
Eliminate redundant work when user reloads a page.
In the process I've also fully separated index.arc from the current-station
hack. Now only ui.arc is infected.
=-=301 - Tue Jan 26 10:57:08 PST 2010
A function called station was a bad idea. Go all the way, evict
current-station out of index.arc. It's ok to refer to userinfo* in ui.arc. All
tests passing. Navigation working, feedback links working, reloading a station
doesn't change the doc on the user.
=-=302 - Tue Jan 26 11:18:40 PST 2010

Long overdue: replace weird or='s with inittab.
=-=303 - Tue Jan 26 11:52:51 PST 2010

Bugfix: now we use the station variable for more than the feedback link, so
/doc can't just set it to nil.
=-=304 - Tue Jan 26 11:54:06 PST 2010

Fucking refill-metadata is killing us. New threads are not cheap in mzscheme.
Debug why we're updating feed-docs before metadata.
=-=306 - Tue Jan 26 12:04:12 PST 2010
Hmm, just always try to update metadata?
=-=307 - Tue Jan 26 12:06:55 PST 2010
Fixed.

I'd forgotten that persisted is again creating a let scope.
This patch was hard because macros can't need to be at the top level. No do's
or let's or they won't be accessible from outside.

The segfault is back.
=-=308 - Tue Jan 26 14:31:54 PST 2010
