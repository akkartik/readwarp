Test 7 isn't consistent.
=-=2 - Fri Dec  4 18:17:19 PST 2009

Toy examples done. url -> related docs.
Data structures now starting to take shape.

Tests are ugly, code interleaved with data.
We can use more indexes.
Decouple the index like in SQL, so the same code runs faster if the index
exists.
=-=4 - Fri Dec  4 19:14:31 PST 2009

Finished building the index. gen-docs works.
=-=5 - Sat Dec  5 09:47:15 PST 2009
Added agg3 ui to it. Messy that I've added stations to the flat-history model.
  Form to create new station.
  Choose between stations, each station gets its own read-list.
=-=6 - Mon Dec  7 13:22:11 PST 2009

Importing agg3 crawl pipeline. Next step: merge properly.

Vision: crawl a universal set of feeds. Don't wait for entire crawl to import
crawled feeds. Track per-user feeds and feed priorities in userinfo*. Make
agg3 just another station for users who import feeds. Push station selection
to a new screen; add new station form to the left panel when reading. Track
history by station.

Later: screens to manage feeds. Stations for importing email, other data
sources, etc. Discovering new feeds during crawl.
=-=7 - Tue Dec  8 12:06:08 PST 2009

crawl and htmlclean now communicate by fifo.
But it's currently blocking. So htmlclean blocks until input, then just reads
the first input and goes back to waiting. Meanwhile if I add a delay to
htmlclean it blocks crawl instead.
=-=8 - Tue Dec  8 14:11:15 PST 2009
If we stick with the blocking model we need to start the pipeline in reverse
order, from consumer to producer of each fifo.

If any stage dies, all other stages will block.

Will we lose stuff in fifos if we kill arc? Periodically look at files under
urls/
=-=9 - Tue Dec  8 15:06:09 PST 2009
Redefine defscan to run in separate threads, not a single thread.
Also some reorg.
=-=10 - Tue Dec  8 18:16:09 PST 2009

3 Crawl errors fixed.
=-=11 - Tue Dec  8 19:34:06 PST 2009

Instead of printing progress for background threads, maintain a circular
buffer of messages for each.
Not persistent for now.
=-=12 - Tue Dec  8 22:34:02 PST 2009

Focusing on UI.
Yesterday's problem: we want to scan read-list for both gen-docs and rendering
history.
=-=14 - Tue Dec  8 22:48:22 PST 2009

Ok, partial matches now working. Takes too long, though. Do all the work in
one pass. Every page load should do just one pass through docinfo*.
=-=15 - Tue Dec  8 23:24:59 PST 2009
Single pass for site-docs and feed-docs takes test runtime down from 72s to
42s for 13650 items in docinfo. But it's still too much.
=-=16 - Tue Dec  8 23:54:18 PST 2009
All that time is being spent on downcase!
Just add downcase versions of all metadata.
Or cache downcase separately.
=-=17 - Wed Dec  9 00:00:57 PST 2009
Yep, cached downcase and got to within 3x of non-downcase version.
=-=18 - Wed Dec  9 00:04:45 PST 2009

Time to start indexing. It's working, but dies every now and then. I think
it's dying when the pipe breaks.
=-=19 - Wed Dec  9 00:35:19 PST 2009
Ok, found the core dump in keywords.cc - negative index.
=-=21 - Thu Dec 10 00:44:08 PST 2009
Cleanup.
=-=22 - Thu Dec 10 00:46:41 PST 2009

Back to the UI. Refactoring index.arc to always take a user arg.
gen-docs doesn't like docs as arguments. I need to test-drive this..
=-=23 - Fri Dec 11 04:55:14 PST 2009
Done. Rebuilding the index.
=-=24 - Fri Dec 11 08:10:24 PST 2009
